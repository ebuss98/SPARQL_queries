{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "\n",
    "data = pd.read_csv('RS/data.csv', sep = ', ', engine = 'python')\n",
    "placeData = pd.read_csv('RS/context_place.csv', sep = ', ', engine = 'python')\n",
    "dayData = pd.read_csv('RS/context_day.csv', sep = ', ', engine = 'python')\n",
    "headerList = [\"movieNum\", \"movieName\"]\n",
    "movieNameData = pd.read_csv('RS/movie_names.csv', sep = ', ', engine = 'python', names = headerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Movie 7': 3.425, 'Movie 12': 2.383, 'Movie 20': 3.184, 'Movie 22': 2.682, 'Movie 29': 2.359}\n"
     ]
    }
   ],
   "source": [
    "notRated = -1\n",
    "def queryForRecommendations(movieNameData, keys):\n",
    "    for i in range(0,len(keys)):\n",
    "        API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "        movie_name = movieNameData['movieName'][movieNameData['movieNum'] == keys[i]].to_csv(header=None, index=False)\n",
    "        params = {\n",
    "            'action' : 'wbsearchentities',\n",
    "            'format' : 'json',\n",
    "            'language' : 'en',\n",
    "            'search': movie_name\n",
    "        }\n",
    "        res = requests.get(API_ENDPOINT, params = params)\n",
    "        res.json()['search'][0]['description']\n",
    "        movieShortCut = res.json()['search'][0]['id']\n",
    "        sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "        sparql_query = \"\"\"\n",
    "        #defaultView:Map\n",
    "        SELECT ?actor ?coords ?actorLabel ?placeLabel\n",
    "        WHERE {\n",
    "          wd:%s wdt:P161 ?actor .\n",
    "          ?actor wdt:P21 wd:Q6581072 .\n",
    "          ?actor wdt:P19 ?place .\n",
    "          ?place wdt:P625 ?coords .\n",
    "          SERVICE wikibase:label {bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}\n",
    "              }\n",
    "\n",
    "        \"\"\" % (movieShortCut)\n",
    "\n",
    "        sparql.setQuery(sparql_query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "        results_df = pd.json_normalize(results['results']['bindings'])\n",
    "        output = results_df[['actorLabel.value', 'placeLabel.value']]\n",
    "        output.columns = ['Actress name', 'Place of birth']\n",
    "        print('\\n' + movie_name)\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "def findSimilaritiesAndMean(userIndex, data, notRatedMarker):\n",
    "    sims = []\n",
    "    for i in range(0, data.shape[0]):\n",
    "        if i == userIndex:\n",
    "            continue\n",
    "        userInfo = data.iloc[[i,userIndex]]\n",
    "        userInfo = userInfo.drop(columns=[userInfo.columns[0]])\n",
    "        userInfo = userInfo.transpose()\n",
    "        infoWithRates = userInfo[(userInfo[i] != notRatedMarker) & (userInfo[userIndex] != notRatedMarker)]\n",
    "        user = data.iloc[[i]].drop(columns=[data.iloc[[i]].columns[0]]).transpose()\n",
    "        userMean = round(user[(user[i]!= notRatedMarker)].mean(),3)\n",
    "        numerator = 0\n",
    "        denom1 = 0\n",
    "        denom2 = 0\n",
    "        for k in range(0,infoWithRates.shape[0]):\n",
    "            numerator += infoWithRates.iloc[k, 0] * infoWithRates.iloc[k, 1]\n",
    "            denom1 += infoWithRates.iloc[k, 0] ** 2\n",
    "            denom2 += infoWithRates.iloc[k, 1] ** 2\n",
    "        sim = numerator / (math.sqrt(denom1) * math.sqrt(denom2))\n",
    "        sim = round(sim,3)\n",
    "        sims.append((i, userMean, sim))\n",
    "    dtype = [('user', int), ('mean', float), ('sim', float)]\n",
    "    sims = np.array(sims, dtype=dtype)\n",
    "    sims = np.sort(sims, order = 'sim')[::-1]\n",
    "    return sims\n",
    "\n",
    "\n",
    "def makeRecomendation(userIndex, data, notRatedMarker):\n",
    "    sims = findSimilaritiesAndMean(userIndex,data,notRatedMarker)\n",
    "    myUser = data.iloc[[userIndex]].drop(columns=[data.iloc[[userIndex]].columns[0]]).transpose()\n",
    "    myUserMean = myUser[(myUser[userIndex] != notRatedMarker)].mean()\n",
    "    unrated = myUser[myUser[userIndex] == notRatedMarker].index\n",
    "    rates = {}\n",
    "    for i in range(0,unrated.shape[0]):\n",
    "        count = 0\n",
    "        absSum = 0\n",
    "        nominator = 0\n",
    "        for k in range(0, sims.shape[0]):\n",
    "            if count == 4:\n",
    "                break\n",
    "            rate = data[unrated[i]][sims[k][0]]\n",
    "            if rate == notRatedMarker:\n",
    "                continue\n",
    "            else:\n",
    "                count +=1\n",
    "                nominator += sims[k][2] * (rate - sims[k][1])\n",
    "                absSum += abs(sims[k][2])\n",
    "        newRate = round(myUserMean + nominator / absSum, 3)\n",
    "        rates[unrated[i]] = newRate[userIndex]\n",
    "    return rates\n",
    "\n",
    "\n",
    "result1 = makeRecomendation(2, data, notRated)\n",
    "print(result1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Lord of the Rings: The Return of the King\n",
      "\n",
      "     Actress name Place of birth\n",
      "0  Cate Blanchett      Melbourne\n",
      "1    Miranda Otto       Brisbane\n",
      "2    Sarah McLeod       Putāruru\n",
      "3       Liv Tyler    East Harlem\n",
      "\n",
      "Forrest Gump\n",
      "\n",
      "            Actress name            Place of birth\n",
      "0       Marla Sucharetza             New York City\n",
      "1     Mary Ellen Trainor             San Francisco\n",
      "2        Elizabeth Hanks               Los Angeles\n",
      "3        Hilary Chaplain                    Boston\n",
      "4         Deborah McTeer            South Carolina\n",
      "5          Hanna R. Hall                    Denver\n",
      "6           Robin Wright                    Dallas\n",
      "7      Jacqueline Lovell             Beverly Hills\n",
      "8   Siobhan Fallon Hogan                  Syracuse\n",
      "9            Emily Carey  London Borough of Barnet\n",
      "10           Isabel Rose           Upper East Side\n",
      "11           Sally Field                  Pasadena\n",
      "12        Hallie D'Amore                    Harvey\n",
      "13        Ione M. Telech                  Beaufort\n",
      "14           Nora Dunfee                   Belmont\n",
      "\n",
      "City of God\n",
      "\n",
      "        Actress name   Place of birth\n",
      "0        Alice Braga        São Paulo\n",
      "1      Olívia Araújo        São Paulo\n",
      "2  Roberta Rodrigues   Rio de Janeiro\n",
      "3        Mary Sheyla   Rio de Janeiro\n",
      "4  Graziella Moretto           Santos\n",
      "5      Dani Ornellas  Duque de Caxias\n",
      "\n",
      "Star Wars: Episode IV - A New Hope\n",
      "\n",
      "     Actress name Place of birth\n",
      "0   Carrie Fisher        Burbank\n",
      "1  Shelagh Fraser         Purley\n",
      "\n",
      "Leon: The Professional\n",
      "\n",
      "      Actress name Place of birth\n",
      "0  Natalie Portman      Jerusalem\n",
      "1     Ellen Greene       Brooklyn\n"
     ]
    }
   ],
   "source": [
    "queryForRecommendations(movieNameData, list(result.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekendAdvice(userIndex, data, placeData, dayData, notRatedMarker):\n",
    "    weekendHomeFilms = pd.DataFrame()\n",
    "    sims = findSimilaritiesAndMean(userIndex, data, notRatedMarker)\n",
    "    for i in range(0,4):\n",
    "        newdf = pd.concat([data.iloc[[sims[i][0]]], placeData.iloc[[sims[i][0]]], dayData.iloc[[sims[i][0]]]], ignore_index=True)\n",
    "        newdf = newdf.drop(columns=[newdf.columns[0], newdf.columns[newdf.shape[1]-1]]).transpose()\n",
    "        newdf = newdf[((newdf[2] == 'Sun') | (newdf[2] == 'Sat')) & (newdf[1] == 'h')]\n",
    "        weekendHomeFilms = pd.concat([weekendHomeFilms, newdf], ignore_index=False)\n",
    "    return weekendHomeFilms[weekendHomeFilms[0] == weekendHomeFilms[0].max()].index[0]\n",
    "\n",
    "res2 = weekendAdvice(2,data, placeData, dayData, notRated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"user\": 3,\n",
      "    \"1\": {\n",
      "        \"Movie 7\": 3.425,\n",
      "        \"Movie 12\": 2.383,\n",
      "        \"Movie 20\": 3.184,\n",
      "        \"Movie 22\": 2.682,\n",
      "        \"Movie 29\": 2.359\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"Movie_name\": \"Movie 1\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "task1 = json.dumps(result1, sort_keys=True, indent=4)\n",
    "user = 3\n",
    "task2 = json.dumps(res2, sort_keys=True, indent=4) \n",
    "result = json.dumps({'user': user,'1': result1, '2': {'Movie_name': res2}}, indent=4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
